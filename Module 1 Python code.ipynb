{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c462a0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Termination criteria for the corner sub-pixel refinement process\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0), ..., (6,5,0)\n",
    "# Adjust the following parameters according to the chessboard\n",
    "checkerboard_size = (7, 5)\n",
    "objp = np.zeros((checkerboard_size[0]*checkerboard_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:checkerboard_size[0], 0:checkerboard_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "objpoints = []  # 3d points in real-world space\n",
    "imgpoints = []  # 2d points in image plane\n",
    "\n",
    "# List of calibration images\n",
    "images = glob.glob('captured_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, checkerboard_size, None)\n",
    "\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, checkerboard_size, corners2, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Camera calibration\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4643a34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load an image to undistort\n",
    "img_to_undistort = cv2.imread('captured_images/image_18.jpg')\n",
    "h, w = img_to_undistort.shape[:2]\n",
    "new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "# Undistort\n",
    "dst = cv2.undistort(img_to_undistort, mtx, dist, None, new_camera_mtx)\n",
    "\n",
    "# Crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imwrite('undistorted_image.jpg', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e769a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square size in pixels: 124.19742584228516\n",
      "Square size in mm: 26.849553228124034\n"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "ret, corners = cv2.findChessboardCorners(gray, (5, 7), None)\n",
    "\n",
    "# Focal length in pixels (assuming fx and fy are approximately the same)\n",
    "focal_length_pixels = (mtx[0, 0] + mtx[1, 1]) / 2  # Average of fx and fy\n",
    "\n",
    "distance_to_object = 440\n",
    "\n",
    "if ret:\n",
    "    # Measure the size of a square\n",
    "    square_size_pixels = np.linalg.norm(corners[2] - corners[3])\n",
    "    print(f\"Square size in pixels: {square_size_pixels}\")\n",
    "\n",
    "    # Convert pixels to real-world units based on known square size (e.g., 27mm)\n",
    "   \n",
    "    square_size_mm = (square_size_pixels / focal_length_pixels) * distance_to_object\n",
    "\n",
    "    print(f\"Square size in mm: {square_size_mm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc09ab30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration error: 0.15044677187596633 mm\n"
     ]
    }
   ],
   "source": [
    "known_square_size_mm = 27  # \n",
    "error = abs(square_size_mm - known_square_size_mm)\n",
    "print(f\"Calibration error: {error} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8971678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a9b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the chessboard image\n",
    "img = cv2.imread('captured_images/image_2.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define the chessboard size\n",
    "chessboard_size = (5, 7)\n",
    "\n",
    "# Find the chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, chessboard_size, None)\n",
    "\n",
    "# If found, refine the corner positions\n",
    "if ret:\n",
    "    corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "    \n",
    "    # Draw and display the corners\n",
    "    cv2.drawChessboardCorners(img, chessboard_size, corners2, ret)\n",
    "    cv2.imshow('Corners', img)\n",
    "    cv2.waitKey(5)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97657073",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = corners2[0].ravel()  # Top-left corner in the image\n",
    "p2 = corners2[7].ravel()  # Top-right corner in the image\n",
    "p3 = corners2[-1].ravel()  # Bottom-right corner in the image\n",
    "p4 = corners2[-8].ravel()  # Bottom-left corner in the image\n",
    "\n",
    "# 2D image points\n",
    "img_points = np.array([p1, p2, p3, p4])\n",
    "\n",
    "# 3D real-world points\n",
    "obj_points = np.array([[0, 0, 0], [216, 0, 0], [216, 162, 0], [0, 162, 0]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "504a23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, rvecs, tvecs = cv2.solvePnP(obj_points, img_points, mtx, dist)\n",
    "\n",
    "# Convert rotation vectors to rotation matrix\n",
    "R_mtx, jac = cv2.Rodrigues(rvecs)\n",
    "\n",
    "# Now, R_mtx is the rotation matrix and tvecs is the translation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73c4aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "# Assuming R_mtx is the rotation matrix obtained earlier\n",
    "euler_angles = rotation_matrix_to_euler_angles(R_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f958ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Matrix:\n",
      "[[2.02100114e+03 0.00000000e+00 9.28608282e+02]\n",
      " [0.00000000e+00 2.04959675e+03 4.87634022e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "---------------------------------------------------------------------\n",
      "Extrinsic Rotation Matrix:\n",
      "[[-0.19161793 -0.86009458  0.4727789 ]\n",
      " [ 0.37292705  0.38177235  0.84568037]\n",
      " [-0.90785901  0.33835956  0.2475981 ]]\n",
      "---------------------------------------------------------------------\n",
      "Extrinsic Translation Vector:\n",
      "[[ 118.65053037]\n",
      " [-116.9752828 ]\n",
      " [ 577.21351039]]\n",
      "---------------------------------------------------------------------\n",
      "Rotation angles (degrees) around x, y, z axes:\n",
      "[ 53.80481484  65.21113943 117.19507323]\n"
     ]
    }
   ],
   "source": [
    "print(\"Intrinsic Matrix:\")\n",
    "print(mtx)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Extrinsic Rotation Matrix:\")\n",
    "print(R_mtx)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Extrinsic Translation Vector:\")\n",
    "print(tvecs)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Rotation angles (degrees) around x, y, z axes:\")\n",
    "print(np.degrees(euler_angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd44ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring object dimension\n",
    "\n",
    "def measure_object_dimension(frame, mtx, dist, distance_to_object):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blur the image to reduce noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Edge detection\n",
    "    edged = cv2.Canny(blur, 35, 125)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort contours based on their area, keeping only the largest\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:1]\n",
    "    \n",
    "\n",
    "    for c in contours:\n",
    "        # Approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        \n",
    "        # If the approximated contour has four points, assume it's a rectangle (or similar)\n",
    "        if len(approx) == 4:\n",
    "            # Draw the contour\n",
    "            cv2.drawContours(frame, [approx], -1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Compute the bounding box of the contour and use it to compute the object dimensions\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "            width_pixels = w  \n",
    "            height_pixels = h  \n",
    "\n",
    "        # Calculate real-world dimensions\n",
    "            width_mm = (width_pixels * distance_to_object) / mtx[0, 0]  # Using f_x from the camera matrix\n",
    "            height_mm = (height_pixels * distance_to_object) / mtx[1, 1]  # Using f_y from the camera matrix\n",
    "\n",
    "            # Display the dimensions on the image\n",
    "            cv2.putText(frame, f\"Width: {width_mm:.2f} mm\", (x, y - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Height: {height_mm:.2f} mm\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "402c3be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Call the object measurement function on the current frame\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m measure_object_dimension(frame, mtx, dist,\u001b[38;5;241m350\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Display the resulting frame\u001b[39;00m\n\u001b[1;32m     21\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n",
      "Cell \u001b[0;32mIn[9], line 38\u001b[0m, in \u001b[0;36mmeasure_object_dimension\u001b[0;34m(frame, mtx, dist, distance_to_object)\u001b[0m\n\u001b[1;32m     35\u001b[0m height_mm \u001b[38;5;241m=\u001b[39m (height_pixels \u001b[38;5;241m*\u001b[39m distance_to_object) \u001b[38;5;241m/\u001b[39m mtx[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Using f_y from the camera matrix\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Display the dimensions on the image\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWidth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth_mm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (x, y \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m20\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     39\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeight: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight_mm\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (x, y \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Real time video capturing \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    \n",
    "        # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "        # If frame is read correctly, ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "\n",
    "        # Call the object measurement function on the current frame\n",
    "    measure_object_dimension(frame, mtx, dist,350)\n",
    "\n",
    "        # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    # release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d9d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save to file\n",
    "np.save('camera_mtx.npy', mtx)\n",
    "np.save('dist_coeffs.npy', dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ee877d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
